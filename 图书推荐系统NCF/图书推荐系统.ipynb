{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92cc1925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图书推荐系统\n",
    "# 任务描述：建立一个隐式推荐算法，可以预测用户交互的下一本书。\n",
    "# 数据集:使用了Goodbooks-10k数据集，包含了10000本图书和53424个用户共约6M条交互记录。\n",
    "# 方法概述：首先加载数据，并划分训练集和验证集。搭建NCF(Neural Collaborative Filtering)模型，并构建负样本，最终按照模型输出的评分进行排序，做出最终的推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116c7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82adcf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#全局参数，随机种子，图像尺寸\n",
    "seed = 114514\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "hidden_dim = 16\n",
    "epochs = 1\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bddd44f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.数据准备\n",
    "# 1.1 数据说明\n",
    "# 1.2 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77106c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共53424个用户，10000本图书，5869631条记录\n"
     ]
    }
   ],
   "source": [
    "# 1.1 加载数据\n",
    "# 观察样本数量和稀疏度。\n",
    "df = pd.read_csv('train_dataset.csv')\n",
    "print('共{}个用户，{}本图书，{}条记录'.format(max(df['user_id'])+1, max(df['item_id'])+1, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25ff79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id\n",
       "0        0      257\n",
       "1        0      267\n",
       "2        0     5555\n",
       "3        0     3637\n",
       "4        0     1795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cc67771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2数据预处理\n",
    "# 构建Dataset类\n",
    "# 构建负样本\n",
    "# 划分测试集与验证集\n",
    "# 构建对应的Dataloader\n",
    "import tqdm\n",
    "class Goodbooks(Dataset):\n",
    "    def __init__(self, df, mode='training', negs = 99):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "\n",
    "        self.book_nums = max(df['item_id'])+1\n",
    "        self.user_nums = max(df['user_id'])+1\n",
    "\n",
    "        self._init_dataset()\n",
    "    \n",
    "    def _init_dataset(self):\n",
    "        self.Xs = []\n",
    "\n",
    "        self.user_book_map = {}\n",
    "        for i in range(self.user_nums):\n",
    "            self.user_book_map[i] = []\n",
    "\n",
    "        for index, row in self.df.iterrows():\n",
    "            user_id, book_id = row\n",
    "            self.user_book_map[user_id].append(book_id)\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            for user, items in tqdm.tqdm(self.user_book_map.items()):\n",
    "                for item in items[:-1]:\n",
    "                    self.Xs.append((user, item, 1))\n",
    "                    for _ in range(3):\n",
    "                        while True:\n",
    "                            neg_sample = random.randint(0, self.book_nums-1)\n",
    "                            if neg_sample not in self.user_book_map[user]:\n",
    "                                self.Xs.append((user, neg_sample, 0))\n",
    "                                break\n",
    "\n",
    "        elif self.mode == 'validation':\n",
    "            for user, items in tqdm.tqdm(self.user_book_map.items()):\n",
    "                if len(items) == 0:\n",
    "                    continue\n",
    "                self.Xs.append((user, items[-1]))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if self.mode == 'training':\n",
    "            user_id, book_id, label = self.Xs[index]\n",
    "            return user_id, book_id, label\n",
    "        elif self.mode == 'validation':\n",
    "            user_id, book_id = self.Xs[index]\n",
    "\n",
    "            negs = list(random.sample(\n",
    "                list(set(range(self.book_nums)) - set(self.user_book_map[user_id])),\n",
    "                k=99\n",
    "            ))\n",
    "            return user_id, book_id, torch.LongTensor(negs)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644bc13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 53424/53424 [00:39<00:00, 1368.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 53424/53424 [00:00<00:00, 959646.49it/s]\n"
     ]
    }
   ],
   "source": [
    "#建立训练和验证dataloader\n",
    "traindataset = Goodbooks(df, 'training')\n",
    "validdataset = Goodbooks(df, 'validation')\n",
    "\n",
    "trainloader = DataLoader(traindataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, num_workers=0)\n",
    "validloader = DataLoader(validdataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb52faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.模型构建\n",
    "# NCF模型由GMF部分和MLP部分组成。\n",
    "\n",
    "# Embedding Layer: 嵌入层，将稀疏的one-hot用户/物品向量转化为稠密的低维向量\n",
    "# GMF Layer: 通过传统的矩阵分解算法，将以用户和物品的嵌入向量做内积。有效地提取浅层特征。\n",
    "# MLP Layer: 通过n层全连接层，提取深层特征。\n",
    "# Concatenation Layer: 将GMF和MLP输出的结果做concat，结合其中的深层和浅层信息。\n",
    "# Output Layer: 输出层，输出用户-物品对的最终评分。\n",
    "# 构建模型\n",
    "class NCFModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, user_num, item_num, mlp_layer_num=4, weight_decay = 1e-5, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.user_num = user_num\n",
    "        self.item_num = item_num\n",
    "        self.mlp_layer_num = mlp_layer_num\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout=dropout\n",
    "\n",
    "        self.mlp_user_embedding = torch.nn.Embedding(user_num, hidden_dim * (2 ** (self.mlp_layer_num - 1)))\n",
    "        self.mlp_item_embedding = torch.nn.Embedding(item_num, hidden_dim * (2 ** (self.mlp_layer_num - 1)))\n",
    "\n",
    "        self.gmf_user_embedding = torch.nn.Embedding(user_num, hidden_dim)\n",
    "        self.gmf_item_embedding = torch.nn.Embedding(item_num, hidden_dim)\n",
    "\n",
    "        mlp_Layers = []\n",
    "        input_size = int(hidden_dim*(2 ** (self.mlp_layer_num)))\n",
    "        for i in range(self.mlp_layer_num):\n",
    "            mlp_Layers.append(torch.nn.Linear(int(input_size), int(input_size / 2)))\n",
    "            mlp_Layers.append(torch.nn.Dropout(self.dropout))\n",
    "            mlp_Layers.append(torch.nn.ReLU())\n",
    "            input_size /= 2\n",
    "        self.mlp_layers = torch.nn.Sequential(*mlp_Layers)\n",
    "\n",
    "        self.output_layer = torch.nn.Linear(2*self.hidden_dim, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_gmf_embedding = self.gmf_user_embedding(user)\n",
    "        item_gmf_embedding = self.gmf_item_embedding(item)\n",
    "\n",
    "        user_mlp_embedding = self.mlp_user_embedding(user)\n",
    "        item_mlp_embedding = self.mlp_item_embedding(item)\n",
    "\n",
    "        gmf_output = user_gmf_embedding * item_gmf_embedding\n",
    "\n",
    "        mlp_input = torch.cat([user_mlp_embedding, item_mlp_embedding], dim=-1)\n",
    "        mlp_output = self.mlp_layers(mlp_input)\n",
    "\n",
    "        output = torch.sigmoid(self.output_layer(torch.cat([gmf_output, mlp_output], dim=-1))).squeeze(-1)\n",
    "\n",
    "        # return -r_pos_neg + reg\n",
    "        return output\n",
    "    \n",
    "    def predict(self, user, item):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            user_gmf_embedding = self.gmf_user_embedding(user)\n",
    "            item_gmf_embedding = self.gmf_item_embedding(item)\n",
    "\n",
    "            user_mlp_embedding = self.mlp_user_embedding(user)\n",
    "            item_mlp_embedding = self.mlp_item_embedding(item)\n",
    "\n",
    "            gmf_output = user_gmf_embedding.unsqueeze(1) * item_gmf_embedding\n",
    "\n",
    "            user_mlp_embedding = user_mlp_embedding.unsqueeze(1).expand(-1, item_mlp_embedding.shape[1], -1)\n",
    "            mlp_input = torch.cat([user_mlp_embedding, item_mlp_embedding], dim=-1)\n",
    "            mlp_output = self.mlp_layers(mlp_input)\n",
    "\n",
    "        output = torch.sigmoid(self.output_layer(torch.cat([gmf_output, mlp_output], dim=-1))).squeeze(-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e8c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.模型训练&4.模型评估\n",
    "# 训练策略\n",
    "# 训练模型，固定步数会计算准确率\n",
    "# 模型保存\n",
    "# 可视化训练过程，对比训练集和验证集的准确率\n",
    "model = NCFModel(hidden_dim, traindataset.user_nums, traindataset.book_nums).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit = torch.nn.BCELoss()\n",
    "\n",
    "loss_for_plot = []\n",
    "hits_for_plot = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    losses = []\n",
    "    for index, data in enumerate(trainloader):\n",
    "        user, item, label = data\n",
    "        user, item, label = user.to(device), item.to(device), label.to(device).float()\n",
    "        y_ = model(user, item).squeeze()\n",
    "\n",
    "        loss = crit(y_, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.detach().cpu().item()) \n",
    "\n",
    "    hits = []\n",
    "    for index, data in enumerate(validloader):\n",
    "        user, pos, neg = data\n",
    "        pos = pos.unsqueeze(1)\n",
    "        all_data = torch.cat([pos, neg], dim=-1)\n",
    "        output = model.predict(user.to(device), all_data.to(device)).detach().cpu()\n",
    "        \n",
    "        for batch in output:\n",
    "            if 0 not in (-batch).argsort()[:10]:\n",
    "                hits.append(0)\n",
    "            else:\n",
    "                hits.append(1)\n",
    "    print('Epoch {} finished, average loss {}, hits@20 {}'.format(epoch, sum(losses)/len(losses), sum(hits)/len(hits)))\n",
    "    loss_for_plot.append(sum(losses)/len(losses))\n",
    "    hits_for_plot.append(sum(hits)/len(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931fe456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型保存\n",
    "torch.save(model.state_dict(), 'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d488d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = list(range(1, len(hits_for_plot)+1))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(x, loss_for_plot, 'r')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('acc')\n",
    "plt.plot(x, hits_for_plot, 'r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d7e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.模型预测\n",
    "# 加载测试数据\n",
    "# 生成提交文件\n",
    "df = pd.read_csv('test_dataset.csv')\n",
    "user_for_test = df['user_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_item_id = []\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i, i+n]\n",
    "\n",
    "f = open('submission.csv', 'w', encoding='utf-8')\n",
    "\n",
    "for user in user_for_test:\n",
    "    #将用户已经交互过的物品排除\n",
    "    user_visited_items = traindataset.user_book_map[user]\n",
    "    items_for_predict = list(set(range(traindataset.book_nums)) - set(user_visited_items))\n",
    "    \n",
    "    results = []\n",
    "    user = torch.Tensor([user]).to(device)\n",
    "\n",
    "    for batch in chunks(items_for_predict, 64):\n",
    "        batch = torch.Tensor(batch).unsqueeze(0).to(device)\n",
    "\n",
    "        result = model(user, batch).view(-1).detach().cpu()\n",
    "        results.append(result)\n",
    "    \n",
    "    results = torch.cat(results, dim=-1)\n",
    "    predict_item_id = (-results).argsort()[:10]\n",
    "    list(map(lambda x: f.write('{},{}\\n'.format(user.cpu().item(), x)), predict_item_id))\n",
    "\n",
    "f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8910244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
