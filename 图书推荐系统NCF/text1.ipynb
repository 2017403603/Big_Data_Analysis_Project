{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "#全局参数，随机种子，图像尺寸\n",
    "seed = 114514\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "hidden_dim = 16\n",
    "epochs = 20\n",
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共53424个用户，10000本图书，5869631条记录\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/datafountain/train_dataset.csv')\n",
    "print('共{}个用户，{}本图书，{}条记录'.format(max(df['user_id'])+1, max(df['item_id'])+1, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id\n",
       "0        0      257\n",
       "1        0      267\n",
       "2        0     5555\n",
       "3        0     3637\n",
       "4        0     1795"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "class Goodbooks(Dataset):\n",
    "    def __init__(self, df, mode='training', negs = 99):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.book_nums = max(df['item_id'])+1\n",
    "        self.user_nums = max(df['user_id'])+1\n",
    "        self._init_dataset()\n",
    "    \n",
    "    def _init_dataset(self):\n",
    "        self.Xs = []\n",
    "        self.user_book_map = {}\n",
    "        for i in range(self.user_nums):\n",
    "            self.user_book_map[i] = []\n",
    "        for index, row in self.df.iterrows():\n",
    "            user_id, book_id = row\n",
    "            self.user_book_map[user_id].append(book_id)\n",
    "            \n",
    "        if self.mode == 'training':\n",
    "            for user, items in tqdm.tqdm(self.user_book_map.items()):\n",
    "                for item in items[:-1]:\n",
    "                    self.Xs.append((user, item, 1))\n",
    "                    for _ in range(3):\n",
    "                        while True:\n",
    "                            neg_sample = random.randint(0, self.book_nums-1)\n",
    "                            if neg_sample not in self.user_book_map[user]:\n",
    "                                self.Xs.append((user, neg_sample, 0))\n",
    "                                break\n",
    "        elif self.mode == 'validation':\n",
    "            for user, items in tqdm.tqdm(self.user_book_map.items()):\n",
    "                if len(items) == 0:\n",
    "                    continue\n",
    "                self.Xs.append((user, items[-1]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'training':\n",
    "            user_id, book_id, label = self.Xs[index]\n",
    "            return user_id, book_id, label\n",
    "        elif self.mode == 'validation':\n",
    "            user_id, book_id = self.Xs[index]\n",
    "            negs = list(random.sample(\n",
    "                list(set(range(self.book_nums)) - set(self.user_book_map[user_id])),\n",
    "                k=99\n",
    "            ))\n",
    "            return user_id, book_id, torch.LongTensor(negs)\n",
    "    def __len__(self):\n",
    "        return len(self.Xs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53424/53424 [01:29<00:00, 599.76it/s]\n",
      "100%|██████████| 53424/53424 [00:00<00:00, 436993.06it/s]\n"
     ]
    }
   ],
   "source": [
    "  #建立训练和验证dataloader\n",
    "traindataset = Goodbooks(df, 'training')\n",
    "validdataset = Goodbooks(df, 'validation')\n",
    "\n",
    "trainloader = DataLoader(traindataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, num_workers=0)\n",
    "validloader = DataLoader(validdataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, num_workers=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "class NCFModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, user_num, item_num, mlp_layer_num=6, weight_decay = 1e-5, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.user_num = user_num\n",
    "        self.item_num = item_num\n",
    "        self.mlp_layer_num = mlp_layer_num\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout=dropout\n",
    "        self.mlp_user_embedding = torch.nn.Embedding(user_num, hidden_dim * (2 ** (self.mlp_layer_num - 1)))\n",
    "        self.mlp_item_embedding = torch.nn.Embedding(item_num, hidden_dim * (2 ** (self.mlp_layer_num - 1)))\n",
    "\n",
    "        self.gmf_user_embedding = torch.nn.Embedding(user_num, hidden_dim)\n",
    "        self.gmf_item_embedding = torch.nn.Embedding(item_num, hidden_dim)\n",
    "\n",
    "        mlp_Layers = []\n",
    "        input_size = int(hidden_dim*(2 ** (self.mlp_layer_num)))\n",
    "        for i in range(self.mlp_layer_num):\n",
    "            mlp_Layers.append(torch.nn.Linear(int(input_size), int(input_size / 2)))\n",
    "            mlp_Layers.append(torch.nn.Dropout(self.dropout))\n",
    "            mlp_Layers.append(torch.nn.ReLU())\n",
    "            input_size /= 2\n",
    "        self.mlp_layers = torch.nn.Sequential(*mlp_Layers)\n",
    "        self.output_layer = torch.nn.Linear(2*self.hidden_dim, 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_gmf_embedding = self.gmf_user_embedding(user)\n",
    "        item_gmf_embedding = self.gmf_item_embedding(item)\n",
    "\n",
    "        user_mlp_embedding = self.mlp_user_embedding(user)\n",
    "        item_mlp_embedding = self.mlp_item_embedding(item)\n",
    "\n",
    "        gmf_output = user_gmf_embedding * item_gmf_embedding\n",
    "\n",
    "        mlp_input = torch.cat([user_mlp_embedding, item_mlp_embedding], dim=-1)\n",
    "        mlp_output = self.mlp_layers(mlp_input)\n",
    "\n",
    "        output = torch.sigmoid(self.output_layer(torch.cat([gmf_output, mlp_output], dim=-1))).squeeze(-1)\n",
    "        # return -r_pos_neg + reg\n",
    "        return output\n",
    "\n",
    "    def predict(self, user, item):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            user_gmf_embedding = self.gmf_user_embedding(user)\n",
    "            item_gmf_embedding = self.gmf_item_embedding(item)\n",
    "\n",
    "            user_mlp_embedding = self.mlp_user_embedding(user)\n",
    "            item_mlp_embedding = self.mlp_item_embedding(item)\n",
    "\n",
    "            gmf_output = user_gmf_embedding.unsqueeze(1) * item_gmf_embedding\n",
    "\n",
    "            user_mlp_embedding = user_mlp_embedding.unsqueeze(1).expand(-1, item_mlp_embedding.shape[1], -1)\n",
    "            mlp_input = torch.cat([user_mlp_embedding, item_mlp_embedding], dim=-1)\n",
    "            mlp_output = self.mlp_layers(mlp_input)\n",
    "\n",
    "        output = torch.sigmoid(self.output_layer(torch.cat([gmf_output, mlp_output], dim=-1))).squeeze(-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 finished, average loss 0.447723874439892, hits@20 0.380989817310572\n",
      "Epoch 1 finished, average loss 0.36973981534616207, hits@20 0.5105757711889788\n",
      "Epoch 2 finished, average loss 0.3041636566867606, hits@20 0.6072177298592393\n",
      "Epoch 3 finished, average loss 0.26241439088267393, hits@20 0.6535826594788859\n",
      "Epoch 4 finished, average loss 0.2348265324319175, hits@20 0.6775606469002695\n",
      "Epoch 5 finished, average loss 0.2135938015464746, hits@20 0.690214135968853\n",
      "Epoch 6 finished, average loss 0.19502752743543347, hits@20 0.6956611260856543\n",
      "Epoch 7 finished, average loss 0.17828809743563473, hits@20 0.7058812518718179\n",
      "Epoch 8 finished, average loss 0.16236734930130745, hits@20 0.7053197064989518\n",
      "Epoch 9 finished, average loss 0.14719087681191986, hits@20 0.7059561245882\n",
      "Epoch 10 finished, average loss 0.13345298735821673, hits@20 0.7026055705300989\n",
      "Epoch 11 finished, average loss 0.11955288015133833, hits@20 0.6955675351901767\n",
      "Epoch 12 finished, average loss 0.10693430094118886, hits@20 0.6873128182090447\n",
      "Epoch 13 finished, average loss 0.09691506869972906, hits@20 0.6890723270440252\n",
      "Epoch 14 finished, average loss 0.08808230766485459, hits@20 0.6888477088948787\n",
      "Epoch 15 finished, average loss 0.07639567394561338, hits@20 0.686975890985325\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11759/3667863027.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lightning/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = NCFModel(hidden_dim, traindataset.user_nums, traindataset.book_nums).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit = torch.nn.BCELoss()\n",
    "best_hits = 0\n",
    "loss_for_plot = []\n",
    "hits_for_plot = []\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    losses = []\n",
    "    for index, data in enumerate(trainloader):\n",
    "        user, item, label = data\n",
    "        user, item, label = user.to(device), item.to(device), label.to(device).float()\n",
    "        y_ = model(user, item).squeeze()\n",
    "\n",
    "        loss = crit(y_, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.detach().cpu().item()) \n",
    "    hits = []\n",
    "    for index, data in enumerate(validloader):\n",
    "        user, pos, neg = data\n",
    "        pos = pos.unsqueeze(1)\n",
    "        all_data = torch.cat([pos, neg], dim=-1)\n",
    "        output = model.predict(user.to(device), all_data.to(device)).detach().cpu()\n",
    "        \n",
    "        for batch in output:\n",
    "            if 0 not in (-batch).argsort()[:10]:\n",
    "                hits.append(0)\n",
    "            else:\n",
    "                hits.append(1)\n",
    "    print('Epoch {} finished, average loss {}, hits@20 {}'.format(epoch, sum(losses)/len(losses), sum(hits)/len(hits)))\n",
    "    loss_for_plot.append(sum(losses)/len(losses))\n",
    "    hits_for_plot.append(sum(hits)/len(hits))\n",
    "    epoch_hits = sum(hits)/len(hits)\n",
    "    if epoch_hits > best_hits:\n",
    "        best_hits = sum(hits)/len(hits)\n",
    "        torch.save(model.state_dict(), 'best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCFModel(\n",
       "  (mlp_user_embedding): Embedding(53424, 512)\n",
       "  (mlp_item_embedding): Embedding(10000, 512)\n",
       "  (gmf_user_embedding): Embedding(53424, 16)\n",
       "  (gmf_item_embedding): Embedding(10000, 16)\n",
       "  (mlp_layers): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (10): Dropout(p=0.5, inplace=False)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (13): Dropout(p=0.5, inplace=False)\n",
       "    (14): ReLU()\n",
       "    (15): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (16): Dropout(p=0.5, inplace=False)\n",
       "    (17): ReLU()\n",
       "  )\n",
       "  (output_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型保存\n",
    "# torch.save(model.state_dict(), 'model.\n",
    "model = NCFModel(hidden_dim, traindataset.user_nums, traindataset.book_nums).to(device)\n",
    "model.load_state_dict(torch.load('best_model.h5'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hits_for_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_683/104776308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhits_for_plot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hits_for_plot' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = list(range(1, len(hits_for_plot) + 1))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(x, loss_for_plot, 'r')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('acc')\n",
    "plt.plot(x, hits_for_plot, 'r')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i: i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53424/53424 [04:39<00:00, 191.18it/s]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "df = pd.read_csv('datasets/datafountain/test_dataset.csv')\n",
    "user_for_test = df['user_id'].tolist()\n",
    "\n",
    "predict_item_id = []\n",
    "\n",
    "f = open('submission.csv', 'w', encoding='utf-8')\n",
    "f.write('user_id,item_id\\n')\n",
    "for user in tqdm.tqdm(user_for_test):\n",
    "    #将用户已经交互过的物品排除\n",
    "    user_visited_items = traindataset.user_book_map[user]\n",
    "    items_for_predict = list(set(range(traindataset.book_nums)) - set(user_visited_items))\n",
    "    \n",
    "    results = []\n",
    "    user = torch.Tensor([user]).unsqueeze(0).long().to(device)\n",
    "\n",
    "    for batch in chunks(items_for_predict,102400):\n",
    "        \n",
    "        batch = torch.Tensor(batch).unsqueeze(0).long().to(device)\n",
    "        _,batch_len = batch.shape\n",
    "        user_predicts_tensor = user.expand(1,batch_len)\n",
    "\n",
    "        result = model(user_predicts_tensor, batch).view(-1).detach().cpu()\n",
    "        results.append(result)\n",
    "    results = torch.cat(results, dim=-1)\n",
    "    predict_item_id = (-results).argsort()[:10]\n",
    "    list(map(lambda x: f.write('{},{}\\n'.format(user.cpu().item(), x)), predict_item_id))\n",
    "\n",
    "f.flush()\n",
    "f.close()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b52ac74c0a051b2ba9b9ffd3e54cf769649c7037a5f720100e6ee2c0f9fd453"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
